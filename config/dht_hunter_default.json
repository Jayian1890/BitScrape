// DHT Hunter Configuration File
// This file contains all configurable settings for the DHT Hunter application.
// Modify these settings to customize the behavior of the application.

{
  "general": {
    // Directory for storing configuration and data files
    "configDir": "~/dht-hunter",
    
    // Log file name
    "logFile": "dht_hunter.log",
    
    // Log level (trace, debug, info, warning, error, critical)
    "logLevel": "info"
  },
  
  "dht": {
    // UDP port for DHT communication
    "port": 6881,
    
    // K-bucket size (maximum number of nodes in a bucket)
    "kBucketSize": 16,
    
    // Alpha parameter for parallel lookups (number of concurrent requests)
    "alpha": 3,
    
    // Maximum number of nodes to store in a lookup result
    "maxResults": 8,
    
    // Token rotation interval in seconds (5 minutes as per BEP-5)
    "tokenRotationInterval": 300,
    
    // Bucket refresh interval in minutes
    "bucketRefreshInterval": 60,
    
    // Maximum number of iterations for node lookups
    "maxIterations": 10,
    
    // Maximum number of queries for node lookups
    "maxQueries": 100,
    
    // Bootstrap nodes for initial DHT connection
    "bootstrapNodes": [
      "dht.aelitis.com:6881",
      "dht.transmissionbt.com:6881",
      "dht.libtorrent.org:25401",
      "router.utorrent.com:6881"
    ]
  },
  
  "network": {
    // Transaction timeout in seconds
    "transactionTimeout": 30,
    
    // Maximum number of concurrent transactions
    "maxTransactions": 1024,
    
    // MTU size for UDP packets
    "mtuSize": 1400
  },
  
  "web": {
    // Web server port
    "port": 8080,
    
    // Web root directory
    "webRoot": "web"
  },
  
  "persistence": {
    // Save interval in minutes
    "saveInterval": 60,
    
    // File paths for persistent data
    "routingTablePath": "routing_table.dat",
    "peerStoragePath": "peer_storage.dat",
    "metadataPath": "metadata.dat",
    "nodeIDPath": "node_id.dat"
  },
  
  "crawler": {
    // Number of nodes to crawl in parallel
    "parallelCrawls": 10,
    
    // Refresh interval in seconds
    "refreshInterval": 15,
    
    // Maximum number of nodes to store
    "maxNodes": 1000000,
    
    // Maximum number of info hashes to track
    "maxInfoHashes": 1000000,
    
    // Whether to automatically start crawling on initialization
    "autoStart": true
  },
  
  "metadata": {
    // Processing interval in seconds
    "processingInterval": 5,
    
    // Maximum number of concurrent metadata acquisitions
    "maxConcurrentAcquisitions": 5,
    
    // Acquisition timeout in seconds
    "acquisitionTimeout": 60,
    
    // Maximum number of retry attempts
    "maxRetryCount": 3,
    
    // Base delay for retry in seconds (exponential backoff)
    "retryDelayBase": 300
  },
  
  "event": {
    // Whether to enable logging
    "enableLogging": true,
    
    // Whether to enable component communication
    "enableComponent": true,
    
    // Whether to enable statistics
    "enableStatistics": true,
    
    // Whether to process events asynchronously
    "asyncProcessing": false,
    
    // Maximum size of the event queue
    "eventQueueSize": 1000,
    
    // Number of processing threads for asynchronous processing
    "processingThreads": 1
  },
  
  "logging": {
    // Whether to output logs to the console
    "consoleOutput": true,
    
    // Whether to output logs to a file
    "fileOutput": true,
    
    // Whether to include timestamps in log messages
    "includeTimestamp": true,
    
    // Whether to include severity levels in log messages
    "includeSeverity": true,
    
    // Whether to include source components in log messages
    "includeSource": true
  }
}
